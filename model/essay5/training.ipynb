{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 14:15:15.987817: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training_set.tsv\", sep='\\t', encoding='ISO-8859-1');\n",
    "df.dropna(axis=1,inplace=True)\n",
    "df.drop(columns=['domain1_score','rater1_domain1','rater2_domain1'],inplace=True,axis=1)\n",
    "df.head()\n",
    "temp = pd.read_csv(\"Processed_data.csv\")\n",
    "temp.drop(\"Unnamed: 0\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>A long time ago when I was in third grade I ha...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Softball has to be one of the single most grea...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>Some people like making people laugh, I love ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>\"LAUGHTER\"  @CAPS1 I hang out with my friends,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>Well ima tell a story about the time i got @CA...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          8  A long time ago when I was in third grade I ha...   \n",
       "1         2          8  Softball has to be one of the single most grea...   \n",
       "2         3          8   Some people like making people laugh, I love ...   \n",
       "3         4          8  \"LAUGHTER\"  @CAPS1 I hang out with my friends,...   \n",
       "4         5          8  Well ima tell a story about the time i got @CA...   \n",
       "\n",
       "   domain1_score  \n",
       "0              6  \n",
       "1              8  \n",
       "2              7  \n",
       "3              5  \n",
       "4              4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['domain1_score']=temp['final_score']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A long time ago when I was in third grade I had a friend @PERSON2 who's mom was in a bad mood. She never laughed and she never smiled. Every time I saw her I would smile at her and all she would do was frown and keep walking. At first I didn't know she was a grouch i just thought she didn't like me or something.When @PERSON2 told me his mom was a grouch I started to laugh and laugh. He asked me what was so funny i told him that i thought his mom didn't like me or something because every time I see his mom I would smile at her and all she will do is frown and walk away. That made my friend laugh we were cracking up so hard that we got in trouble in class.   The next day @PERSON2 and I were eating lunch at school when he says to me &lt;hey your pretty good at making people laugh&gt;. I said &lt;no I am not my jokesare horrible&gt;. He said &lt;@CAPS1 lets put them to the test go up to some one new to this school&gt;. I said @CAPS1 so we went around the whole school looking for a new student unfortunately we couldn't find one we heard the bell ring and we ran to our class. We sat in the back of the classroom its only @PERSON2 and I and anempty seat between us. We were excited because our teacher @PERSON1 was going to show us a movie. @PERSON1 got the front of the room andclass today I have an announcement we have a new student in our class say hello to @LOCATION1. @ORGANIZATION1 walked through the door. @PERSON1 told @ORGANIZATION1 shecould sit in the back in between @PERSON2 and I. She sat down turned to the both of us and said hello. @PERSON2 gave me a look that said tell her the joke and @CAPS3 him a thumbs up. I turned to @LOCATION1 and said hi I'm @CAPS4 do you want to hear a joke. @ORGANIZATION1 said yeah sure. I started &lt;@CAPS5 knockshe said &lt;who's thereI said &lt;booshe said &lt;boo who?I said &lt;oh don't cry I am right here&gt;. At first she didn't laugh because she didn't get it but duringthe middle of the movie she said &lt;ohhhh I get itand she started to laugh. @PERSON2 turned to me and said &lt;I told you so&gt;.   @PERSON2 got this crazy idea that if I spent the night at his house that I could make his mom laugh or at least make her smile. I said &lt;@CAPS1 sounds like a plan&gt;. I asked mt mom if it was @CAPS1 if I could spend the night at @PERSON2 house she said &lt;yeah just make sure its @CAPS1 with his mom&gt;. @PERSON2 asked his mom she said it was @CAPS1. When I got to @PERSON2 house the first thing we did was play video games. When it was dinner time we all sat down at the table to eat @PERSON2 and I were on one side and his parents on the other. When we started eating @PERSON2 told me to tell the joke to his parents i said @CAPS1. So I said to them &lt;@CAPS5 @CAPS5&gt;they replied &lt;who's thereI said &lt;boothey said &lt;boo who?I said &lt;oh don't cry I am right here&gt;. His parents started to laugh and laugh and they keptlaughing for like five minutes. @PERSON2 turned to me and yelled it worked his mom asked what worked. @PERSON2 explained everything to them. His mom told usthat her mom had recently died and that's why she was in a bad mood. After dinner we went to bed and fell asleep. The next morning when my mom came to pick me up she asked me how the sleep over went. I said it was fun I made people laugh. She said @CAPS1 but laughter isn't going to help you clean your roomall i could say was gosh darn it.             FIN\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['essay'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>final_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>spell_err_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>A long time ago when I was in third grade I ha...</td>\n",
       "      <td>6</td>\n",
       "      <td>A long time ago I third grade I friend s mom b...</td>\n",
       "      <td>2364</td>\n",
       "      <td>674</td>\n",
       "      <td>36</td>\n",
       "      <td>3.507418</td>\n",
       "      <td>59</td>\n",
       "      <td>134</td>\n",
       "      <td>158</td>\n",
       "      <td>49</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Softball has to be one of the single most grea...</td>\n",
       "      <td>8</td>\n",
       "      <td>Softball one single greatest sports alive  pla...</td>\n",
       "      <td>3067</td>\n",
       "      <td>779</td>\n",
       "      <td>28</td>\n",
       "      <td>3.937099</td>\n",
       "      <td>18</td>\n",
       "      <td>142</td>\n",
       "      <td>163</td>\n",
       "      <td>52</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>Some people like making people laugh, I love i...</td>\n",
       "      <td>7</td>\n",
       "      <td>Some people like making people laugh  I love  ...</td>\n",
       "      <td>3426</td>\n",
       "      <td>861</td>\n",
       "      <td>39</td>\n",
       "      <td>3.979094</td>\n",
       "      <td>31</td>\n",
       "      <td>161</td>\n",
       "      <td>174</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>\"LAUGHTER\" I hang out with my friends, the one...</td>\n",
       "      <td>5</td>\n",
       "      <td>LAUGHTER  I hang friends  one thing best laug...</td>\n",
       "      <td>2547</td>\n",
       "      <td>697</td>\n",
       "      <td>30</td>\n",
       "      <td>3.654232</td>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>155</td>\n",
       "      <td>31</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>Well ima tell a story about the time i got dow...</td>\n",
       "      <td>4</td>\n",
       "      <td>Well ima tell story time got town  When headin...</td>\n",
       "      <td>2093</td>\n",
       "      <td>618</td>\n",
       "      <td>24</td>\n",
       "      <td>3.386731</td>\n",
       "      <td>50</td>\n",
       "      <td>120</td>\n",
       "      <td>174</td>\n",
       "      <td>41</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          8  A long time ago when I was in third grade I ha...   \n",
       "1         2          8  Softball has to be one of the single most grea...   \n",
       "2         3          8  Some people like making people laugh, I love i...   \n",
       "3         4          8  \"LAUGHTER\" I hang out with my friends, the one...   \n",
       "4         5          8  Well ima tell a story about the time i got dow...   \n",
       "\n",
       "   final_score                                        clean_essay  char_count  \\\n",
       "0            6  A long time ago I third grade I friend s mom b...        2364   \n",
       "1            8  Softball one single greatest sports alive  pla...        3067   \n",
       "2            7  Some people like making people laugh  I love  ...        3426   \n",
       "3            5   LAUGHTER  I hang friends  one thing best laug...        2547   \n",
       "4            4  Well ima tell story time got town  When headin...        2093   \n",
       "\n",
       "   word_count  sent_count  avg_word_len  spell_err_count  noun_count  \\\n",
       "0         674          36      3.507418               59         134   \n",
       "1         779          28      3.937099               18         142   \n",
       "2         861          39      3.979094               31         161   \n",
       "3         697          30      3.654232               19         124   \n",
       "4         618          24      3.386731               50         120   \n",
       "\n",
       "   adj_count  verb_count  adv_count  \n",
       "0        158          49         26  \n",
       "1        163          52         71  \n",
       "2        174          57         62  \n",
       "3        155          31         63  \n",
       "4        174          41         76  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Dataset\n",
    "y = df['domain1_score']\n",
    "df.drop('domain1_score',inplace=True,axis=1)\n",
    "X=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = X_train['essay'].tolist()\n",
    "test_e = X_test['essay'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents=[]\n",
    "test_sents=[]\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def sent2word(x):\n",
    "    x=re.sub(\"[^A-Za-z]\",\" \",x)\n",
    "    x.lower()\n",
    "    filtered_sentence = [] \n",
    "    words=x.split()\n",
    "    for w in words:\n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "def essay2word(essay):\n",
    "    essay = essay.strip()\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw = tokenizer.tokenize(essay)\n",
    "    final_words=[]\n",
    "    for i in raw:\n",
    "        if(len(i)>0):\n",
    "            final_words.append(sent2word(i))\n",
    "    return final_words\n",
    "\n",
    "for i in train_e:\n",
    "    train_sents+=essay2word(i)\n",
    "\n",
    "for i in test_e:\n",
    "    test_sents+=essay2word(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17388"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In', 'ninth', 'grade', 'I', 'required', 'give', 'speech', 'book']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing WORD2VEC and LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/gnm3d9hn21d8t3q08syhwsdw0000gp/T/ipykernel_6915/1462232201.py:15: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "#Training Word2Vec model\n",
    "num_features = 300 \n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3\n",
    "\n",
    "model = Word2Vec(train_sents, \n",
    "                 workers=num_workers, \n",
    "                 vector_size=num_features, \n",
    "                 min_count = min_word_count, \n",
    "                 window = context, \n",
    "                 sample = downsampling)\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVec(words, model, num_features):\n",
    "    vec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    noOfWords = 0.\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    for i in words:\n",
    "        if i in index2word_set:\n",
    "            noOfWords += 1\n",
    "            vec = np.add(vec,model.wv.get_vector(i))        \n",
    "    vec = np.divide(vec,noOfWords)\n",
    "    return vec\n",
    "\n",
    "\n",
    "def getVecs(essays, model, num_features):\n",
    "    c=0\n",
    "    essay_vecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for i in essays:\n",
    "        essay_vecs[c] = makeVec(i, model, num_features)\n",
    "        c+=1\n",
    "    return essay_vecs\n",
    "\n",
    "\n",
    "clean_train=[]\n",
    "for i in train_e:\n",
    "    clean_train.append(sent2word(i))\n",
    "training_vectors = getVecs(clean_train, model, num_features)\n",
    "\n",
    "clean_test=[] \n",
    "\n",
    "for i in test_e:\n",
    "    clean_test.append(sent2word(i))\n",
    "testing_vectors = getVecs(clean_test, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 14:15:52.822292: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_vectors = np.array(training_vectors)\n",
    "testing_vectors = np.array(testing_vectors)\n",
    "\n",
    "# Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
    "testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
    "lstm_model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING AND PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8/8 [==============================] - 4s 14ms/step - loss: 35.9734 - mae: 5.8980\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 16.8137 - mae: 3.8661\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 4.0861 - mae: 1.7159\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.1039 - mae: 1.1662\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.8953 - mae: 1.0873\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6514 - mae: 1.0257\n",
      "Epoch 7/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.0259 - mae: 1.1074\n",
      "Epoch 8/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.7436 - mae: 1.0545\n",
      "Epoch 9/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.9063 - mae: 1.0905\n",
      "Epoch 10/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7864 - mae: 1.0567\n",
      "Epoch 11/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.7392 - mae: 1.0618\n",
      "Epoch 12/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.8030 - mae: 1.0655\n",
      "Epoch 13/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.8711 - mae: 1.0806\n",
      "Epoch 14/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7604 - mae: 1.0580\n",
      "Epoch 15/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6951 - mae: 1.0394\n",
      "Epoch 16/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6860 - mae: 1.0120\n",
      "Epoch 17/150\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7561 - mae: 1.0543\n",
      "Epoch 18/150\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.7246 - mae: 1.0325\n",
      "Epoch 19/150\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.8331 - mae: 1.0723\n",
      "Epoch 20/150\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.6272 - mae: 1.0373\n",
      "Epoch 21/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.8437 - mae: 1.1187\n",
      "Epoch 22/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.8776 - mae: 1.0674\n",
      "Epoch 23/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.8180 - mae: 1.0777\n",
      "Epoch 24/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.5358 - mae: 0.9993\n",
      "Epoch 25/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.7886 - mae: 1.0728\n",
      "Epoch 26/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6475 - mae: 1.0315\n",
      "Epoch 27/150\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.6510 - mae: 1.0339\n",
      "Epoch 28/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.7346 - mae: 1.0375\n",
      "Epoch 29/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.7776 - mae: 1.0508\n",
      "Epoch 30/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.7995 - mae: 1.0499\n",
      "Epoch 31/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.8242 - mae: 1.0784\n",
      "Epoch 32/150\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.8035 - mae: 1.0695\n",
      "Epoch 33/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.8484 - mae: 1.0689\n",
      "Epoch 34/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6817 - mae: 1.0113\n",
      "Epoch 35/150\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.6552 - mae: 1.0260\n",
      "Epoch 36/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6635 - mae: 1.0328\n",
      "Epoch 37/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.7746 - mae: 1.0457\n",
      "Epoch 38/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6078 - mae: 1.0004\n",
      "Epoch 39/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6699 - mae: 1.0273\n",
      "Epoch 40/150\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.6079 - mae: 1.0246\n",
      "Epoch 41/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6243 - mae: 1.0093\n",
      "Epoch 42/150\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.8476 - mae: 1.0822\n",
      "Epoch 43/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6908 - mae: 1.0338\n",
      "Epoch 44/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.7987 - mae: 1.0668\n",
      "Epoch 45/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6157 - mae: 1.0029\n",
      "Epoch 46/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.8252 - mae: 1.0716\n",
      "Epoch 47/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.7765 - mae: 1.0638\n",
      "Epoch 48/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6829 - mae: 1.0471\n",
      "Epoch 49/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7032 - mae: 1.0300\n",
      "Epoch 50/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6600 - mae: 1.0147\n",
      "Epoch 51/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6738 - mae: 1.0322\n",
      "Epoch 52/150\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.6790 - mae: 1.0377\n",
      "Epoch 53/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.7738 - mae: 1.0629\n",
      "Epoch 54/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6846 - mae: 1.0363\n",
      "Epoch 55/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.5869 - mae: 1.0000\n",
      "Epoch 56/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.9037 - mae: 1.0908\n",
      "Epoch 57/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7757 - mae: 1.0786\n",
      "Epoch 58/150\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.6532 - mae: 1.0437\n",
      "Epoch 59/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.7808 - mae: 1.0597\n",
      "Epoch 60/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.5633 - mae: 0.9940\n",
      "Epoch 61/150\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 1.7721 - mae: 1.0699\n",
      "Epoch 62/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7410 - mae: 1.0489\n",
      "Epoch 63/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.5373 - mae: 0.9830\n",
      "Epoch 64/150\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.8664 - mae: 1.1028\n",
      "Epoch 65/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.8093 - mae: 1.0891\n",
      "Epoch 66/150\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.6960 - mae: 1.0494\n",
      "Epoch 67/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6320 - mae: 1.0324\n",
      "Epoch 68/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.5371 - mae: 0.9929\n",
      "Epoch 69/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6165 - mae: 0.9830\n",
      "Epoch 70/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.7881 - mae: 1.0606\n",
      "Epoch 71/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.7117 - mae: 1.0446\n",
      "Epoch 72/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6071 - mae: 1.0191\n",
      "Epoch 73/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7026 - mae: 1.0308\n",
      "Epoch 74/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6766 - mae: 1.0324\n",
      "Epoch 75/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6226 - mae: 1.0343\n",
      "Epoch 76/150\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.7055 - mae: 1.0250\n",
      "Epoch 77/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.7152 - mae: 1.0475\n",
      "Epoch 78/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7027 - mae: 1.0158\n",
      "Epoch 79/150\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.7881 - mae: 1.0974\n",
      "Epoch 80/150\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.5679 - mae: 1.0071\n",
      "Epoch 81/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6813 - mae: 1.0324\n",
      "Epoch 82/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6612 - mae: 1.0368\n",
      "Epoch 83/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6222 - mae: 1.0082\n",
      "Epoch 84/150\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6381 - mae: 1.0190\n",
      "Epoch 85/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6193 - mae: 1.0234\n",
      "Epoch 86/150\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.6435 - mae: 1.0120\n",
      "Epoch 87/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7103 - mae: 1.0510\n",
      "Epoch 88/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7415 - mae: 1.0494\n",
      "Epoch 89/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6216 - mae: 1.0113\n",
      "Epoch 90/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6925 - mae: 1.0449\n",
      "Epoch 91/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.5911 - mae: 1.0149\n",
      "Epoch 92/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.5687 - mae: 0.9726\n",
      "Epoch 93/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6466 - mae: 1.0174\n",
      "Epoch 94/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6348 - mae: 0.9915\n",
      "Epoch 95/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6249 - mae: 1.0105\n",
      "Epoch 96/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6687 - mae: 1.0267\n",
      "Epoch 97/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6303 - mae: 1.0163\n",
      "Epoch 98/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6755 - mae: 1.0377\n",
      "Epoch 99/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6039 - mae: 0.9911\n",
      "Epoch 100/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6176 - mae: 1.0105\n",
      "Epoch 101/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.5986 - mae: 1.0218\n",
      "Epoch 102/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6783 - mae: 1.0526\n",
      "Epoch 103/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6952 - mae: 1.0321\n",
      "Epoch 104/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6905 - mae: 1.0287\n",
      "Epoch 105/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6966 - mae: 1.0250\n",
      "Epoch 106/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.5514 - mae: 0.9904\n",
      "Epoch 107/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6462 - mae: 0.9963\n",
      "Epoch 108/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.7576 - mae: 1.0616\n",
      "Epoch 109/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6765 - mae: 1.0305\n",
      "Epoch 110/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7720 - mae: 1.0458\n",
      "Epoch 111/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6447 - mae: 1.0369\n",
      "Epoch 112/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.5107 - mae: 0.9596\n",
      "Epoch 113/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.5778 - mae: 0.9961\n",
      "Epoch 114/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6059 - mae: 1.0158\n",
      "Epoch 115/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6931 - mae: 1.0232\n",
      "Epoch 116/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6301 - mae: 1.0047\n",
      "Epoch 117/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6607 - mae: 1.0300\n",
      "Epoch 118/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.5518 - mae: 0.9895\n",
      "Epoch 119/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.5347 - mae: 0.9752\n",
      "Epoch 120/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6518 - mae: 1.0299\n",
      "Epoch 121/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.7165 - mae: 1.0617\n",
      "Epoch 122/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.5965 - mae: 1.0163\n",
      "Epoch 123/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.7007 - mae: 1.0341\n",
      "Epoch 124/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6439 - mae: 1.0056\n",
      "Epoch 125/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.7884 - mae: 1.0709\n",
      "Epoch 126/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.7210 - mae: 1.0433\n",
      "Epoch 127/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6685 - mae: 1.0227\n",
      "Epoch 128/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6529 - mae: 1.0199\n",
      "Epoch 129/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.7600 - mae: 1.0831\n",
      "Epoch 130/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6842 - mae: 1.0408\n",
      "Epoch 131/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6013 - mae: 1.0071\n",
      "Epoch 132/150\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6435 - mae: 1.0153\n",
      "Epoch 133/150\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.5122 - mae: 0.9768\n",
      "Epoch 134/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6985 - mae: 1.0606\n",
      "Epoch 135/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7050 - mae: 1.0517\n",
      "Epoch 136/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6386 - mae: 1.0039\n",
      "Epoch 137/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6218 - mae: 1.0166\n",
      "Epoch 138/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6874 - mae: 1.0458\n",
      "Epoch 139/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7102 - mae: 1.0439\n",
      "Epoch 140/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7512 - mae: 1.0439\n",
      "Epoch 141/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7230 - mae: 1.0441\n",
      "Epoch 142/150\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.6097 - mae: 1.0086\n",
      "Epoch 143/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.5639 - mae: 0.9973\n",
      "Epoch 144/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7436 - mae: 1.0729\n",
      "Epoch 145/150\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.5160 - mae: 0.9930\n",
      "Epoch 146/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.6524 - mae: 1.0143\n",
      "Epoch 147/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.5895 - mae: 1.0184\n",
      "Epoch 148/150\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6262 - mae: 1.0095\n",
      "Epoch 149/150\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.7249 - mae: 1.0424\n",
      "Epoch 150/150\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6053 - mae: 1.0220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc94088250>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(training_vectors, y_train, batch_size=64, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.save('final_lstm.h5')\n",
    "y_pred = lstm_model.predict(testing_vectors)\n",
    "y_pred = np.around(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "essay_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
