{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 12:12:33.910799: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training_set.tsv\", sep='\\t', encoding='ISO-8859-1');\n",
    "df.dropna(axis=1,inplace=True)\n",
    "df.drop(columns=['domain1_score','rater1_domain1','rater2_domain1'],inplace=True,axis=1)\n",
    "df.head()\n",
    "temp = pd.read_csv(\"Processed_data.csv\")\n",
    "temp.drop(\"Unnamed: 0\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Certain materials being removed from libraries...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Write a persuasive essay to a newspaper reflec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Do you think that libraries should remove cert...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>In @DATE1's world, there are many things found...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>In life you have the 'offensive things'. The l...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          2  Certain materials being removed from libraries...   \n",
       "1         2          2  Write a persuasive essay to a newspaper reflec...   \n",
       "2         3          2  Do you think that libraries should remove cert...   \n",
       "3         4          2  In @DATE1's world, there are many things found...   \n",
       "4         5          2  In life you have the 'offensive things'. The l...   \n",
       "\n",
       "   domain1_score  \n",
       "0              6  \n",
       "1              0  \n",
       "2              2  \n",
       "3              6  \n",
       "4              6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['domain1_score']=temp['final_score']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Certain materials being removed from libraries such as books, music and magazines, shouldn't be removed from the libraries. It gives people a chance to understand how the real world @CAPS2.     Having certain materials such as books and music definitly should not be removed, because most books and music can show most people how bad the statement in the book @CAPS2 or how bad the lyrics are in a song, and help that person to avoid that type of thing that the book or song @CAPS2 saying to the reader or listener. People should give every type of music at least a try and not always doubt what they hear about what people say about that type of music. I always hear about people saying how bad the band @PERSON1 A.M. @CAPS2, just because in the lyrics it talks about drugs and how much cursing each song has. Really the band @CAPS2 talking about one mans life and how he turns his life from being a drug addict to having the best life someone could ever live. People always doubted him and never gave his music a chance. Another example would be @PERSON1's book, '@CAPS1 @CAPS2 @CAPS3 @CAPS4' for it talks about drug addicts, homeless people, people who have been born with disfigured arms or even someone who lost there legs, and telling how beautiful each and everyone of them really are. His book taught me a few things and made me think different about people. It doesn't matter how they look or how they talk, no matter what, that person @CAPS2 beautiful.     As far as movies and magazines has gone within the last few years, I think that the also shouldn't be taken from libraries. I think @CAPS1 for the same reason of how I feel about the books and music. Of course we see previews of movies and think that they @MONTH1 not be good, but libraries shouldn't keep leave them out. Movies @CAPS2 a great way to learn how to treat others and how to act around other people when you don't know how to act. If you act differently around people that you've never been around before, then you could feel embarassed or maybe even get @CAPS4. Movies can help people learn about the real world by seeing how to do those type of things as we get older. Same goes with the magazines, they also help people see what not to do or to help them understand the consequences of something that shouldn't be done. Knowing what to do from a magazine could possible save your life or perhaps maybe even someone elses life.     I don't understand why some libraries would want to banned certain materials to help people understand the things that happen in someone elses life and to help them not make the same mistakes as that person once did.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['essay'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>final_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>spell_err_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Certain materials being removed from libraries...</td>\n",
       "      <td>6</td>\n",
       "      <td>Certain materials removed libraries books  mus...</td>\n",
       "      <td>1999</td>\n",
       "      <td>470</td>\n",
       "      <td>17</td>\n",
       "      <td>4.253191</td>\n",
       "      <td>15</td>\n",
       "      <td>112</td>\n",
       "      <td>95</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Write a persuasive essay to a newspaper reflec...</td>\n",
       "      <td>0</td>\n",
       "      <td>Write persuasive essay newspaper reflecting vi...</td>\n",
       "      <td>636</td>\n",
       "      <td>167</td>\n",
       "      <td>3</td>\n",
       "      <td>3.808383</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Do you think that libraries should remove cert...</td>\n",
       "      <td>2</td>\n",
       "      <td>Do think libraries remove certain materials sh...</td>\n",
       "      <td>864</td>\n",
       "      <td>222</td>\n",
       "      <td>15</td>\n",
       "      <td>3.891892</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>In world, there are many things found offensiv...</td>\n",
       "      <td>6</td>\n",
       "      <td>In world  many things found offensive  Everyon...</td>\n",
       "      <td>2115</td>\n",
       "      <td>468</td>\n",
       "      <td>31</td>\n",
       "      <td>4.519231</td>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>122</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>In life you have the 'offensive things'. The l...</td>\n",
       "      <td>6</td>\n",
       "      <td>In life offensive things   The little stuff ge...</td>\n",
       "      <td>1814</td>\n",
       "      <td>429</td>\n",
       "      <td>35</td>\n",
       "      <td>4.228438</td>\n",
       "      <td>23</td>\n",
       "      <td>107</td>\n",
       "      <td>93</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          2  Certain materials being removed from libraries...   \n",
       "1         2          2  Write a persuasive essay to a newspaper reflec...   \n",
       "2         3          2  Do you think that libraries should remove cert...   \n",
       "3         4          2  In world, there are many things found offensiv...   \n",
       "4         5          2  In life you have the 'offensive things'. The l...   \n",
       "\n",
       "   final_score                                        clean_essay  char_count  \\\n",
       "0            6  Certain materials removed libraries books  mus...        1999   \n",
       "1            0  Write persuasive essay newspaper reflecting vi...         636   \n",
       "2            2  Do think libraries remove certain materials sh...         864   \n",
       "3            6  In world  many things found offensive  Everyon...        2115   \n",
       "4            6  In life offensive things   The little stuff ge...        1814   \n",
       "\n",
       "   word_count  sent_count  avg_word_len  spell_err_count  noun_count  \\\n",
       "0         470          17      4.253191               15         112   \n",
       "1         167           3      3.808383               11          35   \n",
       "2         222          15      3.891892                5          52   \n",
       "3         468          31      4.519231                3          98   \n",
       "4         429          35      4.228438               23         107   \n",
       "\n",
       "   adj_count  verb_count  adv_count  \n",
       "0         95          33         32  \n",
       "1         46          15          6  \n",
       "2         45          17         15  \n",
       "3        122          27         30  \n",
       "4         93          29         30  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Dataset\n",
    "y = df['domain1_score']\n",
    "df.drop('domain1_score',inplace=True,axis=1)\n",
    "X=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = X_train['essay'].tolist()\n",
    "test_e = X_test['essay'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents=[]\n",
    "test_sents=[]\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def sent2word(x):\n",
    "    x=re.sub(\"[^A-Za-z]\",\" \",x)\n",
    "    x.lower()\n",
    "    filtered_sentence = [] \n",
    "    words=x.split()\n",
    "    for w in words:\n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "def essay2word(essay):\n",
    "    essay = essay.strip()\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw = tokenizer.tokenize(essay)\n",
    "    final_words=[]\n",
    "    for i in raw:\n",
    "        if(len(i)>0):\n",
    "            final_words.append(sent2word(i))\n",
    "    return final_words\n",
    "\n",
    "for i in train_e:\n",
    "    train_sents+=essay2word(i)\n",
    "\n",
    "for i in test_e:\n",
    "    test_sents+=essay2word(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25717"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'think',\n",
       " 'take',\n",
       " 'book',\n",
       " 'donated',\n",
       " 'us',\n",
       " 'first',\n",
       " 'place',\n",
       " 'Also',\n",
       " 'I',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'take',\n",
       " 'helps',\n",
       " 'us',\n",
       " 'learn',\n",
       " 'people',\n",
       " 'went',\n",
       " 'lifetime',\n",
       " 'Look',\n",
       " 'try',\n",
       " 'live',\n",
       " 'life',\n",
       " 'would',\n",
       " 'another',\n",
       " 'persons',\n",
       " 'shoes',\n",
       " 'Try',\n",
       " 'see',\n",
       " 'come',\n",
       " 'life',\n",
       " 'style',\n",
       " 'Im',\n",
       " 'big',\n",
       " 'reader',\n",
       " 'anything',\n",
       " 'wants',\n",
       " 'I',\n",
       " 'get',\n",
       " 'one',\n",
       " 'book',\n",
       " 'catches',\n",
       " 'eye',\n",
       " 'sounds',\n",
       " 'good',\n",
       " 'read',\n",
       " 'I',\n",
       " 'look',\n",
       " 'good',\n",
       " 'I',\n",
       " 'would',\n",
       " 'take',\n",
       " 'read',\n",
       " 'long',\n",
       " 'time',\n",
       " 'I',\n",
       " 'want',\n",
       " 'know',\n",
       " 'happens',\n",
       " 'next',\n",
       " 'book',\n",
       " 'So',\n",
       " 'I',\n",
       " 'keep',\n",
       " 'reading',\n",
       " 'reading',\n",
       " 'like',\n",
       " 'middle',\n",
       " 'story',\n",
       " 'teacher',\n",
       " 'makes',\n",
       " 'stop',\n",
       " 'reading',\n",
       " 'I',\n",
       " 'would',\n",
       " 'read',\n",
       " 'long',\n",
       " 'takes',\n",
       " 'right',\n",
       " 'book',\n",
       " 'I',\n",
       " 'like',\n",
       " 'kinds',\n",
       " 'books',\n",
       " 'sports',\n",
       " 'sad',\n",
       " 'emotional',\n",
       " 'books',\n",
       " 'I',\n",
       " 'like',\n",
       " 'reading',\n",
       " 'loud',\n",
       " 'helps',\n",
       " 'understand',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'better']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing WORD2VEC and LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/gnm3d9hn21d8t3q08syhwsdw0000gp/T/ipykernel_5322/1462232201.py:15: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "#Training Word2Vec model\n",
    "num_features = 300 \n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3\n",
    "\n",
    "model = Word2Vec(train_sents, \n",
    "                 workers=num_workers, \n",
    "                 vector_size=num_features, \n",
    "                 min_count = min_word_count, \n",
    "                 window = context, \n",
    "                 sample = downsampling)\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVec(words, model, num_features):\n",
    "    vec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    noOfWords = 0.\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    for i in words:\n",
    "        if i in index2word_set:\n",
    "            noOfWords += 1\n",
    "            vec = np.add(vec,model.wv.get_vector(i))        \n",
    "    vec = np.divide(vec,noOfWords)\n",
    "    return vec\n",
    "\n",
    "\n",
    "def getVecs(essays, model, num_features):\n",
    "    c=0\n",
    "    essay_vecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for i in essays:\n",
    "        essay_vecs[c] = makeVec(i, model, num_features)\n",
    "        c+=1\n",
    "    return essay_vecs\n",
    "\n",
    "\n",
    "clean_train=[]\n",
    "for i in train_e:\n",
    "    clean_train.append(sent2word(i))\n",
    "training_vectors = getVecs(clean_train, model, num_features)\n",
    "\n",
    "clean_test=[] \n",
    "\n",
    "for i in test_e:\n",
    "    clean_test.append(sent2word(i))\n",
    "testing_vectors = getVecs(clean_test, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 12:13:14.530801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_vectors = np.array(training_vectors)\n",
    "testing_vectors = np.array(testing_vectors)\n",
    "\n",
    "# Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
    "testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
    "lstm_model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 1, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING AND PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "20/20 [==============================] - 5s 12ms/step - loss: 16.7243 - mae: 3.6974\n",
      "Epoch 2/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 3.2450 - mae: 1.4577\n",
      "Epoch 3/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.7544 - mae: 1.3281\n",
      "Epoch 4/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.6522 - mae: 1.2998\n",
      "Epoch 5/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.5741 - mae: 1.2700\n",
      "Epoch 6/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.4507 - mae: 1.2513\n",
      "Epoch 7/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.4660 - mae: 1.2463\n",
      "Epoch 8/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.3965 - mae: 1.2208\n",
      "Epoch 9/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.4277 - mae: 1.2258\n",
      "Epoch 10/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.3663 - mae: 1.2077\n",
      "Epoch 11/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.3867 - mae: 1.2115\n",
      "Epoch 12/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.3453 - mae: 1.2145\n",
      "Epoch 13/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.4054 - mae: 1.2270\n",
      "Epoch 14/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2482 - mae: 1.1927\n",
      "Epoch 15/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.3794 - mae: 1.2234\n",
      "Epoch 16/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.3169 - mae: 1.1881\n",
      "Epoch 17/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2557 - mae: 1.1883\n",
      "Epoch 18/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.3430 - mae: 1.2226\n",
      "Epoch 19/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.3305 - mae: 1.1970\n",
      "Epoch 20/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2995 - mae: 1.2002\n",
      "Epoch 21/150\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 2.3252 - mae: 1.1995\n",
      "Epoch 22/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2960 - mae: 1.1977\n",
      "Epoch 23/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2646 - mae: 1.1915\n",
      "Epoch 24/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2623 - mae: 1.1989\n",
      "Epoch 25/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.2419 - mae: 1.1839\n",
      "Epoch 26/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.3071 - mae: 1.1936\n",
      "Epoch 27/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2152 - mae: 1.1758\n",
      "Epoch 28/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.3600 - mae: 1.2155\n",
      "Epoch 29/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2676 - mae: 1.1989\n",
      "Epoch 30/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2804 - mae: 1.1862\n",
      "Epoch 31/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2481 - mae: 1.1995\n",
      "Epoch 32/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1690 - mae: 1.1703\n",
      "Epoch 33/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2939 - mae: 1.1909\n",
      "Epoch 34/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2398 - mae: 1.1772\n",
      "Epoch 35/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2405 - mae: 1.1827\n",
      "Epoch 36/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.3042 - mae: 1.1969\n",
      "Epoch 37/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2774 - mae: 1.1926\n",
      "Epoch 38/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2155 - mae: 1.1813\n",
      "Epoch 39/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.3370 - mae: 1.2226\n",
      "Epoch 40/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.3152 - mae: 1.1924\n",
      "Epoch 41/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2847 - mae: 1.1838\n",
      "Epoch 42/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1735 - mae: 1.1638\n",
      "Epoch 43/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2553 - mae: 1.1955\n",
      "Epoch 44/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2432 - mae: 1.1907\n",
      "Epoch 45/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1931 - mae: 1.1656\n",
      "Epoch 46/150\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 2.2490 - mae: 1.1667\n",
      "Epoch 47/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2727 - mae: 1.1997\n",
      "Epoch 48/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2965 - mae: 1.1989\n",
      "Epoch 49/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2263 - mae: 1.1829\n",
      "Epoch 50/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2117 - mae: 1.1775\n",
      "Epoch 51/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.2047 - mae: 1.1774\n",
      "Epoch 52/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2320 - mae: 1.1785\n",
      "Epoch 53/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1543 - mae: 1.1605\n",
      "Epoch 54/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.2409 - mae: 1.2002\n",
      "Epoch 55/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2234 - mae: 1.1804\n",
      "Epoch 56/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1460 - mae: 1.1616\n",
      "Epoch 57/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2590 - mae: 1.1972\n",
      "Epoch 58/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2317 - mae: 1.1826\n",
      "Epoch 59/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1198 - mae: 1.1663\n",
      "Epoch 60/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1083 - mae: 1.1507\n",
      "Epoch 61/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2381 - mae: 1.1860\n",
      "Epoch 62/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2575 - mae: 1.1945\n",
      "Epoch 63/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2073 - mae: 1.1814\n",
      "Epoch 64/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2684 - mae: 1.1928\n",
      "Epoch 65/150\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 2.1913 - mae: 1.1660\n",
      "Epoch 66/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1449 - mae: 1.1564\n",
      "Epoch 67/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2232 - mae: 1.1765\n",
      "Epoch 68/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2502 - mae: 1.1785\n",
      "Epoch 69/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1357 - mae: 1.1578\n",
      "Epoch 70/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2727 - mae: 1.1932\n",
      "Epoch 71/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2950 - mae: 1.1989\n",
      "Epoch 72/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1388 - mae: 1.1480\n",
      "Epoch 73/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0997 - mae: 1.1567\n",
      "Epoch 74/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.1448 - mae: 1.1477\n",
      "Epoch 75/150\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 2.2030 - mae: 1.1805\n",
      "Epoch 76/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.2087 - mae: 1.1775\n",
      "Epoch 77/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1726 - mae: 1.1694\n",
      "Epoch 78/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1778 - mae: 1.1536\n",
      "Epoch 79/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2615 - mae: 1.1890\n",
      "Epoch 80/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1360 - mae: 1.1524\n",
      "Epoch 81/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1794 - mae: 1.1612\n",
      "Epoch 82/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1341 - mae: 1.1563\n",
      "Epoch 83/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1393 - mae: 1.1540\n",
      "Epoch 84/150\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 2.1602 - mae: 1.1726\n",
      "Epoch 85/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 2.2202 - mae: 1.1631\n",
      "Epoch 86/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2060 - mae: 1.1647\n",
      "Epoch 87/150\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 2.2424 - mae: 1.1793\n",
      "Epoch 88/150\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 2.1318 - mae: 1.1519\n",
      "Epoch 89/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1916 - mae: 1.1782\n",
      "Epoch 90/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1186 - mae: 1.1537\n",
      "Epoch 91/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1573 - mae: 1.1621\n",
      "Epoch 92/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1329 - mae: 1.1616\n",
      "Epoch 93/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1981 - mae: 1.1666\n",
      "Epoch 94/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2191 - mae: 1.1735\n",
      "Epoch 95/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1703 - mae: 1.1764\n",
      "Epoch 96/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2386 - mae: 1.1922\n",
      "Epoch 97/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1759 - mae: 1.1861\n",
      "Epoch 98/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1711 - mae: 1.1632\n",
      "Epoch 99/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1161 - mae: 1.1483\n",
      "Epoch 100/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1191 - mae: 1.1582\n",
      "Epoch 101/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1901 - mae: 1.1613\n",
      "Epoch 102/150\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 2.2092 - mae: 1.1863\n",
      "Epoch 103/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1944 - mae: 1.1709\n",
      "Epoch 104/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1207 - mae: 1.1428\n",
      "Epoch 105/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1366 - mae: 1.1709\n",
      "Epoch 106/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.2092 - mae: 1.1669\n",
      "Epoch 107/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1437 - mae: 1.1661\n",
      "Epoch 108/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.0787 - mae: 1.1421\n",
      "Epoch 109/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1368 - mae: 1.1603\n",
      "Epoch 110/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0520 - mae: 1.1368\n",
      "Epoch 111/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0962 - mae: 1.1343\n",
      "Epoch 112/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0909 - mae: 1.1438\n",
      "Epoch 113/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0531 - mae: 1.1243\n",
      "Epoch 114/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0968 - mae: 1.1445\n",
      "Epoch 115/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1668 - mae: 1.1661\n",
      "Epoch 116/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2018 - mae: 1.1862\n",
      "Epoch 117/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1056 - mae: 1.1500\n",
      "Epoch 118/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1001 - mae: 1.1574\n",
      "Epoch 119/150\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 2.2019 - mae: 1.1811\n",
      "Epoch 120/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1593 - mae: 1.1617\n",
      "Epoch 121/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0804 - mae: 1.1513\n",
      "Epoch 122/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1553 - mae: 1.1638\n",
      "Epoch 123/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1532 - mae: 1.1606\n",
      "Epoch 124/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1782 - mae: 1.1660\n",
      "Epoch 125/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1105 - mae: 1.1457\n",
      "Epoch 126/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.0918 - mae: 1.1350\n",
      "Epoch 127/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.0846 - mae: 1.1490\n",
      "Epoch 128/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1209 - mae: 1.1647\n",
      "Epoch 129/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.1224 - mae: 1.1514\n",
      "Epoch 130/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1639 - mae: 1.1694\n",
      "Epoch 131/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0906 - mae: 1.1477\n",
      "Epoch 132/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0866 - mae: 1.1486\n",
      "Epoch 133/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0832 - mae: 1.1332\n",
      "Epoch 134/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.2058 - mae: 1.1845\n",
      "Epoch 135/150\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 2.0626 - mae: 1.1397\n",
      "Epoch 136/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0998 - mae: 1.1492\n",
      "Epoch 137/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0694 - mae: 1.1420\n",
      "Epoch 138/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1321 - mae: 1.1579\n",
      "Epoch 139/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 2.0795 - mae: 1.1501\n",
      "Epoch 140/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1113 - mae: 1.1476\n",
      "Epoch 141/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1516 - mae: 1.1708\n",
      "Epoch 142/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0952 - mae: 1.1342\n",
      "Epoch 143/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.0661 - mae: 1.1444\n",
      "Epoch 144/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.1391 - mae: 1.1496\n",
      "Epoch 145/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1065 - mae: 1.1543\n",
      "Epoch 146/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.0977 - mae: 1.1445\n",
      "Epoch 147/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.0233 - mae: 1.1143\n",
      "Epoch 148/150\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 2.0105 - mae: 1.1160\n",
      "Epoch 149/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 2.1188 - mae: 1.1611\n",
      "Epoch 150/150\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 2.0413 - mae: 1.1271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa27604d5a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(training_vectors, y_train, batch_size=64, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [3.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [7.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.save('final_lstm.h5')\n",
    "y_pred = lstm_model.predict(testing_vectors)\n",
    "y_pred = np.around(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "essay_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
