{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 14:22:30.788167: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training_set.tsv\", sep='\\t', encoding='ISO-8859-1');\n",
    "df.dropna(axis=1,inplace=True)\n",
    "df.drop(columns=['domain1_score','rater1_domain1','rater2_domain1'],inplace=True,axis=1)\n",
    "df.head()\n",
    "temp = pd.read_csv(\"Processed_data.csv\")\n",
    "temp.drop(\"Unnamed: 0\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Patience is when your waiting .I was patience ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>I am not a patience person, like I canât sit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>One day I was at basketball practice and I was...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>I going to write about a time when I went to t...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>It can be very hard for somebody to be patient...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          7  Patience is when your waiting .I was patience ...   \n",
       "1         2          7  I am not a patience person, like I canât sit...   \n",
       "2         3          7  One day I was at basketball practice and I was...   \n",
       "3         4          7  I going to write about a time when I went to t...   \n",
       "4         5          7  It can be very hard for somebody to be patient...   \n",
       "\n",
       "   domain1_score  \n",
       "0              5  \n",
       "1              4  \n",
       "2              5  \n",
       "3              6  \n",
       "4              4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['domain1_score']=temp['final_score']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Patience is when your waiting .I was patience when in line waiting for lunch .I didnâ\\x80\\x99t c ut any one to eat .I was standing and waiting for my turn .Patience ,some people donâ\\x80\\x99t have it .Lots of people just cut or yell at you because they donâ\\x80\\x99t have  any patience. Sometimes people will push you out of their way .They only do that because they donâ\\x80\\x99t have patience at all. Patience is what people need .People need patience because lots o f feelings get hurt .Everyone should have patience.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['essay'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>final_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>spell_err_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Patience is when your waiting .I was patience ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Patience waiting I patience line waiting lunch...</td>\n",
       "      <td>382</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>4.063830</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>I am not a patience person, like I canât sit...</td>\n",
       "      <td>4</td>\n",
       "      <td>I patience person  like I cant sit sit five mi...</td>\n",
       "      <td>348</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>3.702128</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>One day I was at basketball practice and I was...</td>\n",
       "      <td>5</td>\n",
       "      <td>One day I basketball practice I running team I...</td>\n",
       "      <td>577</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>3.796053</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>I going to write about a time when I went to t...</td>\n",
       "      <td>6</td>\n",
       "      <td>I going write time I went fair  fun  saw ride ...</td>\n",
       "      <td>840</td>\n",
       "      <td>222</td>\n",
       "      <td>13</td>\n",
       "      <td>3.783784</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>It can be very hard for somebody to be patient...</td>\n",
       "      <td>4</td>\n",
       "      <td>It hard somebody patient  If patient  understa...</td>\n",
       "      <td>629</td>\n",
       "      <td>154</td>\n",
       "      <td>12</td>\n",
       "      <td>4.084416</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          7  Patience is when your waiting .I was patience ...   \n",
       "1         2          7  I am not a patience person, like I canât sit...   \n",
       "2         3          7  One day I was at basketball practice and I was...   \n",
       "3         4          7  I going to write about a time when I went to t...   \n",
       "4         5          7  It can be very hard for somebody to be patient...   \n",
       "\n",
       "   final_score                                        clean_essay  char_count  \\\n",
       "0            5  Patience waiting I patience line waiting lunch...         382   \n",
       "1            4  I patience person  like I cant sit sit five mi...         348   \n",
       "2            5  One day I basketball practice I running team I...         577   \n",
       "3            6  I going write time I went fair  fun  saw ride ...         840   \n",
       "4            4  It hard somebody patient  If patient  understa...         629   \n",
       "\n",
       "   word_count  sent_count  avg_word_len  spell_err_count  noun_count  \\\n",
       "0          94           3      4.063830                0          24   \n",
       "1          94           3      3.702128                7          22   \n",
       "2         152           1      3.796053                9          29   \n",
       "3         222          13      3.783784                3          45   \n",
       "4         154          12      4.084416                1          22   \n",
       "\n",
       "   adj_count  verb_count  adv_count  \n",
       "0         26           2          5  \n",
       "1         18           4          7  \n",
       "2         39           9          6  \n",
       "3         55           9         14  \n",
       "4         37          11         17  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Dataset\n",
    "y = df['domain1_score']\n",
    "df.drop('domain1_score',inplace=True,axis=1)\n",
    "X=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1098, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = X_train['essay'].tolist()\n",
    "test_e = X_test['essay'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents=[]\n",
    "test_sents=[]\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def sent2word(x):\n",
    "    x=re.sub(\"[^A-Za-z]\",\" \",x)\n",
    "    x.lower()\n",
    "    filtered_sentence = [] \n",
    "    words=x.split()\n",
    "    for w in words:\n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "def essay2word(essay):\n",
    "    essay = essay.strip()\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw = tokenizer.tokenize(essay)\n",
    "    final_words=[]\n",
    "    for i in raw:\n",
    "        if(len(i)>0):\n",
    "            final_words.append(sent2word(i))\n",
    "    return final_words\n",
    "\n",
    "for i in train_e:\n",
    "    train_sents+=essay2word(i)\n",
    "\n",
    "for i in test_e:\n",
    "    test_sents+=essay2word(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12608"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Patience', 'way']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing WORD2VEC and LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/gnm3d9hn21d8t3q08syhwsdw0000gp/T/ipykernel_7028/1462232201.py:15: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "#Training Word2Vec model\n",
    "num_features = 300 \n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3\n",
    "\n",
    "model = Word2Vec(train_sents, \n",
    "                 workers=num_workers, \n",
    "                 vector_size=num_features, \n",
    "                 min_count = min_word_count, \n",
    "                 window = context, \n",
    "                 sample = downsampling)\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVec(words, model, num_features):\n",
    "    vec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    noOfWords = 0.\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    for i in words:\n",
    "        if i in index2word_set:\n",
    "            noOfWords += 1\n",
    "            vec = np.add(vec,model.wv.get_vector(i))        \n",
    "    vec = np.divide(vec,noOfWords)\n",
    "    return vec\n",
    "\n",
    "\n",
    "def getVecs(essays, model, num_features):\n",
    "    c=0\n",
    "    essay_vecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for i in essays:\n",
    "        essay_vecs[c] = makeVec(i, model, num_features)\n",
    "        c+=1\n",
    "    return essay_vecs\n",
    "\n",
    "\n",
    "clean_train=[]\n",
    "for i in train_e:\n",
    "    clean_train.append(sent2word(i))\n",
    "training_vectors = getVecs(clean_train, model, num_features)\n",
    "\n",
    "clean_test=[] \n",
    "\n",
    "for i in test_e:\n",
    "    clean_test.append(sent2word(i))\n",
    "testing_vectors = getVecs(clean_test, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1098, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 14:24:58.331464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_vectors = np.array(training_vectors)\n",
    "testing_vectors = np.array(testing_vectors)\n",
    "\n",
    "# Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
    "testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
    "lstm_model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1098, 1, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING AND PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "18/18 [==============================] - 4s 11ms/step - loss: 16.0870 - mae: 3.4939\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 3.0387 - mae: 1.4300\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.7958 - mae: 1.3488\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.9378 - mae: 1.3804\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.9022 - mae: 1.3702\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.8562 - mae: 1.3635\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.8080 - mae: 1.3511\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.8673 - mae: 1.3764\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.9237 - mae: 1.3806\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.7874 - mae: 1.3464\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.6673 - mae: 1.3194\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.5497 - mae: 1.2887\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.5775 - mae: 1.2913\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.6085 - mae: 1.3124\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.6758 - mae: 1.3073\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.5724 - mae: 1.2846\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.6176 - mae: 1.2890\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4356 - mae: 1.2569\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.5285 - mae: 1.2777\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.5356 - mae: 1.2874\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4543 - mae: 1.2581\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4990 - mae: 1.2680\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3453 - mae: 1.2241\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.6021 - mae: 1.2922\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4705 - mae: 1.2465\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3850 - mae: 1.2158\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4378 - mae: 1.2485\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4854 - mae: 1.2644\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4694 - mae: 1.2525\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.5517 - mae: 1.2858\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3849 - mae: 1.2280\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.5624 - mae: 1.2731\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4687 - mae: 1.2587\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4932 - mae: 1.2633\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4210 - mae: 1.2387\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4695 - mae: 1.2585\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 2.5431 - mae: 1.2849\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3702 - mae: 1.2472\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4199 - mae: 1.2395\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4621 - mae: 1.2551\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.5356 - mae: 1.2806\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.5785 - mae: 1.2911\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3747 - mae: 1.2387\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4600 - mae: 1.2584\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2.4262 - mae: 1.2398\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4064 - mae: 1.2439\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3570 - mae: 1.2292\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4978 - mae: 1.2634\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4250 - mae: 1.2459\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2.3766 - mae: 1.2281\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3438 - mae: 1.2247\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4493 - mae: 1.2588\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4899 - mae: 1.2706\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3685 - mae: 1.2326\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4422 - mae: 1.2460\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4105 - mae: 1.2508\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3572 - mae: 1.2251\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3931 - mae: 1.2342\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4432 - mae: 1.2432\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2.2576 - mae: 1.2142\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4114 - mae: 1.2357\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3615 - mae: 1.2405\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 2.4984 - mae: 1.2784\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3452 - mae: 1.2282\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3514 - mae: 1.2536\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3524 - mae: 1.2322\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.2818 - mae: 1.2041\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 2.3089 - mae: 1.2283\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3230 - mae: 1.2179\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4677 - mae: 1.2651\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4281 - mae: 1.2497\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3921 - mae: 1.2216\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3704 - mae: 1.2476\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.2748 - mae: 1.2140\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3209 - mae: 1.2328\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4312 - mae: 1.2478\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4907 - mae: 1.2498\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3800 - mae: 1.2270\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3350 - mae: 1.2284\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.2844 - mae: 1.2092\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3960 - mae: 1.2395\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3337 - mae: 1.2266\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3821 - mae: 1.2391\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4197 - mae: 1.2393\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4475 - mae: 1.2466\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3486 - mae: 1.2386\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3502 - mae: 1.2280\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3230 - mae: 1.2264\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3281 - mae: 1.2224\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3416 - mae: 1.2263\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3361 - mae: 1.2307\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3716 - mae: 1.2319\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3741 - mae: 1.2243\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 2.3974 - mae: 1.2471\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.2964 - mae: 1.2245\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3714 - mae: 1.2215\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3423 - mae: 1.2197\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3246 - mae: 1.2260\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.2423 - mae: 1.1998\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.2714 - mae: 1.2149\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3225 - mae: 1.2268\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3213 - mae: 1.2207\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.2535 - mae: 1.2011\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3045 - mae: 1.2323\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4770 - mae: 1.2708\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.1904 - mae: 1.2010\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3184 - mae: 1.2272\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3758 - mae: 1.2408\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3864 - mae: 1.2357\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3248 - mae: 1.2154\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3486 - mae: 1.2380\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.2281 - mae: 1.2046\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3754 - mae: 1.2391\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4334 - mae: 1.2597\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 2.4190 - mae: 1.2437\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2.3932 - mae: 1.2553\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3540 - mae: 1.2337\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 2.2906 - mae: 1.2088\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 2.3613 - mae: 1.2301\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 2.3095 - mae: 1.2093\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.2932 - mae: 1.2234\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3194 - mae: 1.2145\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3630 - mae: 1.2485\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.2993 - mae: 1.2247\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.2859 - mae: 1.2088\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3295 - mae: 1.2284\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3801 - mae: 1.2369\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.4298 - mae: 1.2419\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3216 - mae: 1.2167\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 2.2995 - mae: 1.2138\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3111 - mae: 1.2259\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3285 - mae: 1.2329\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.2785 - mae: 1.2141\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3410 - mae: 1.2192\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.2856 - mae: 1.2135\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3343 - mae: 1.2420\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.2993 - mae: 1.2149\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 2.4557 - mae: 1.2640\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.1872 - mae: 1.1855\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 2.3125 - mae: 1.2264\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3412 - mae: 1.2209\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.2875 - mae: 1.2110\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 2.1997 - mae: 1.1953\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.1986 - mae: 1.1922\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 2.3886 - mae: 1.2445\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3840 - mae: 1.2380\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.2336 - mae: 1.2023\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 2.2416 - mae: 1.2084\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3913 - mae: 1.2394\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.3266 - mae: 1.2281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb52875e770>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(training_vectors, y_train, batch_size=64, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [2.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.save('final_lstm.h5')\n",
    "y_pred = lstm_model.predict(testing_vectors)\n",
    "y_pred = np.around(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "essay_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
