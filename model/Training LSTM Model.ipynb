{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATASET_DIR = './data/'\n",
    "GLOVE_DIR = './glove.6B/'\n",
    "SAVE_DIR = './'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
    "y = X['domain1_score']\n",
    "X = X.dropna(axis=1)\n",
    "X = X.drop(columns=['rater1_domain1', 'rater2_domain1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0              8  \n",
       "1              9  \n",
       "2              7  \n",
       "3             10  \n",
       "4              8  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum and Maximum Scores for each essay set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_scores = [-1, 2, 1, 0, 0, 0]\n",
    "maximum_scores = [-1, 12, 6, 4, 30, 60]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will preprocess all essays and convert them to feature vectors so that they can be fed into the RNN.\n",
    "\n",
    "These are all helper functions used to clean the essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def essay_to_wordlist(essay_v, remove_stopwords):\n",
    "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
    "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
    "    words = essay_v.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return (words)\n",
    "\n",
    "def essay_to_sentences(essay_v, remove_stopwords):\n",
    "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(essay_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    num_words = 0.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            num_words += 1\n",
    "            featureVec = np.add(featureVec,model[word])        \n",
    "    featureVec = np.divide(featureVec,num_words)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a 2-Layer LSTM Model. \n",
    "\n",
    "Note that instead of using sigmoid activation in the output layer we will use\n",
    "Relu since we are not normalising training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/anaconda3/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/anaconda3/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/anaconda3/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/anaconda3/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/anaconda3/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/anaconda3/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Define the model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model on the dataset.\n",
    "\n",
    "We will use 5-Fold Cross Validation and measure the Quadratic Weighted Kappa for each fold.\n",
    "We will then calculate Average Kappa for all the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/py3.6/lib/python3.6/site-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10380/10380 [==============================] - 4s 353us/step - loss: 63.2828 - mean_absolute_error: 4.2864\n",
      "Epoch 2/50\n",
      "10380/10380 [==============================] - 2s 201us/step - loss: 37.6646 - mean_absolute_error: 3.4590\n",
      "Epoch 3/50\n",
      "10380/10380 [==============================] - 2s 207us/step - loss: 32.1144 - mean_absolute_error: 3.3835\n",
      "Epoch 4/50\n",
      "10380/10380 [==============================] - 2s 200us/step - loss: 29.9928 - mean_absolute_error: 3.3701\n",
      "Epoch 5/50\n",
      "10380/10380 [==============================] - 2s 213us/step - loss: 28.2333 - mean_absolute_error: 3.2581\n",
      "Epoch 6/50\n",
      "10380/10380 [==============================] - 2s 219us/step - loss: 26.9968 - mean_absolute_error: 3.2043\n",
      "Epoch 7/50\n",
      "10380/10380 [==============================] - 2s 209us/step - loss: 25.7222 - mean_absolute_error: 3.0487\n",
      "Epoch 8/50\n",
      "10380/10380 [==============================] - 2s 214us/step - loss: 23.7287 - mean_absolute_error: 2.8752\n",
      "Epoch 9/50\n",
      "10380/10380 [==============================] - 2s 216us/step - loss: 21.4737 - mean_absolute_error: 2.7129\n",
      "Epoch 10/50\n",
      "10380/10380 [==============================] - 2s 215us/step - loss: 19.6619 - mean_absolute_error: 2.5893\n",
      "Epoch 11/50\n",
      "10380/10380 [==============================] - 2s 211us/step - loss: 18.4071 - mean_absolute_error: 2.4603\n",
      "Epoch 12/50\n",
      "10380/10380 [==============================] - 2s 218us/step - loss: 16.3878 - mean_absolute_error: 2.3424\n",
      "Epoch 13/50\n",
      "10380/10380 [==============================] - 2s 220us/step - loss: 15.3073 - mean_absolute_error: 2.2422\n",
      "Epoch 14/50\n",
      "10380/10380 [==============================] - 2s 217us/step - loss: 14.2146 - mean_absolute_error: 2.1854\n",
      "Epoch 15/50\n",
      "10380/10380 [==============================] - 2s 230us/step - loss: 13.4587 - mean_absolute_error: 2.1135\n",
      "Epoch 16/50\n",
      "10380/10380 [==============================] - 2s 225us/step - loss: 13.2643 - mean_absolute_error: 2.0870\n",
      "Epoch 17/50\n",
      "10380/10380 [==============================] - 2s 227us/step - loss: 12.9368 - mean_absolute_error: 2.0691\n",
      "Epoch 18/50\n",
      "10380/10380 [==============================] - 2s 229us/step - loss: 12.3465 - mean_absolute_error: 2.0109\n",
      "Epoch 19/50\n",
      "10380/10380 [==============================] - 2s 236us/step - loss: 11.9352 - mean_absolute_error: 1.9702\n",
      "Epoch 20/50\n",
      "10380/10380 [==============================] - 2s 227us/step - loss: 11.4838 - mean_absolute_error: 1.9246\n",
      "Epoch 21/50\n",
      "10380/10380 [==============================] - 2s 232us/step - loss: 10.8916 - mean_absolute_error: 1.8886\n",
      "Epoch 22/50\n",
      "10380/10380 [==============================] - 3s 274us/step - loss: 10.7661 - mean_absolute_error: 1.8548\n",
      "Epoch 23/50\n",
      "10380/10380 [==============================] - 4s 376us/step - loss: 10.8653 - mean_absolute_error: 1.8443\n",
      "Epoch 24/50\n",
      "10380/10380 [==============================] - 6s 559us/step - loss: 10.7278 - mean_absolute_error: 1.8314\n",
      "Epoch 25/50\n",
      "10380/10380 [==============================] - 6s 545us/step - loss: 10.3836 - mean_absolute_error: 1.7990\n",
      "Epoch 26/50\n",
      "10380/10380 [==============================] - 4s 381us/step - loss: 10.3092 - mean_absolute_error: 1.8038\n",
      "Epoch 27/50\n",
      "10380/10380 [==============================] - 3s 302us/step - loss: 9.7414 - mean_absolute_error: 1.7567\n",
      "Epoch 28/50\n",
      "10380/10380 [==============================] - 3s 243us/step - loss: 9.9113 - mean_absolute_error: 1.7514\n",
      "Epoch 29/50\n",
      "10380/10380 [==============================] - 2s 235us/step - loss: 9.4411 - mean_absolute_error: 1.7285\n",
      "Epoch 30/50\n",
      "10380/10380 [==============================] - 3s 243us/step - loss: 9.9703 - mean_absolute_error: 1.7493\n",
      "Epoch 31/50\n",
      "10380/10380 [==============================] - 3s 271us/step - loss: 9.4777 - mean_absolute_error: 1.7144\n",
      "Epoch 32/50\n",
      "10380/10380 [==============================] - 3s 287us/step - loss: 9.3212 - mean_absolute_error: 1.6922\n",
      "Epoch 33/50\n",
      "10380/10380 [==============================] - 3s 302us/step - loss: 9.3914 - mean_absolute_error: 1.6900\n",
      "Epoch 34/50\n",
      "10380/10380 [==============================] - 3s 319us/step - loss: 9.6294 - mean_absolute_error: 1.6955\n",
      "Epoch 35/50\n",
      "10380/10380 [==============================] - 3s 317us/step - loss: 9.3714 - mean_absolute_error: 1.7033\n",
      "Epoch 36/50\n",
      "10380/10380 [==============================] - 3s 320us/step - loss: 9.2189 - mean_absolute_error: 1.6621\n",
      "Epoch 37/50\n",
      "10380/10380 [==============================] - 3s 315us/step - loss: 8.8246 - mean_absolute_error: 1.6439\n",
      "Epoch 38/50\n",
      "10380/10380 [==============================] - 3s 313us/step - loss: 8.6745 - mean_absolute_error: 1.6348\n",
      "Epoch 39/50\n",
      "10380/10380 [==============================] - 3s 288us/step - loss: 9.0007 - mean_absolute_error: 1.6418\n",
      "Epoch 40/50\n",
      "10380/10380 [==============================] - 3s 284us/step - loss: 8.9328 - mean_absolute_error: 1.6367\n",
      "Epoch 41/50\n",
      "10380/10380 [==============================] - 3s 269us/step - loss: 8.9924 - mean_absolute_error: 1.6281\n",
      "Epoch 42/50\n",
      "10380/10380 [==============================] - 3s 256us/step - loss: 8.6616 - mean_absolute_error: 1.6246\n",
      "Epoch 43/50\n",
      "10380/10380 [==============================] - 3s 259us/step - loss: 8.0513 - mean_absolute_error: 1.6040\n",
      "Epoch 44/50\n",
      "10380/10380 [==============================] - 3s 258us/step - loss: 8.3658 - mean_absolute_error: 1.6043\n",
      "Epoch 45/50\n",
      "10380/10380 [==============================] - 3s 274us/step - loss: 8.3464 - mean_absolute_error: 1.6006\n",
      "Epoch 46/50\n",
      "10380/10380 [==============================] - 3s 267us/step - loss: 8.3836 - mean_absolute_error: 1.5876\n",
      "Epoch 47/50\n",
      "10380/10380 [==============================] - 3s 271us/step - loss: 8.4164 - mean_absolute_error: 1.5974\n",
      "Epoch 48/50\n",
      "10380/10380 [==============================] - 3s 270us/step - loss: 7.9826 - mean_absolute_error: 1.5636\n",
      "Epoch 49/50\n",
      "10380/10380 [==============================] - 3s 261us/step - loss: 8.2540 - mean_absolute_error: 1.5709\n",
      "Epoch 50/50\n",
      "10380/10380 [==============================] - 3s 253us/step - loss: 7.9359 - mean_absolute_error: 1.5630\n",
      "Kappa Score: 0.9564162833853098\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/py3.6/lib/python3.6/site-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 4s 387us/step - loss: 65.7659 - mean_absolute_error: 4.3754\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 2s 216us/step - loss: 39.9805 - mean_absolute_error: 3.5379\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 2s 208us/step - loss: 33.5757 - mean_absolute_error: 3.4520\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 2s 217us/step - loss: 30.7659 - mean_absolute_error: 3.4074\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 2s 226us/step - loss: 29.0817 - mean_absolute_error: 3.3246\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 2s 222us/step - loss: 27.6255 - mean_absolute_error: 3.2290\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 2s 219us/step - loss: 26.3084 - mean_absolute_error: 3.0416\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 2s 226us/step - loss: 23.9672 - mean_absolute_error: 2.8700\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 3s 242us/step - loss: 21.1164 - mean_absolute_error: 2.6999\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 3s 286us/step - loss: 18.8781 - mean_absolute_error: 2.5568\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 3s 304us/step - loss: 17.2787 - mean_absolute_error: 2.4131\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 3s 323us/step - loss: 16.7843 - mean_absolute_error: 2.3531\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 3s 308us/step - loss: 15.2831 - mean_absolute_error: 2.2458\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 3s 301us/step - loss: 14.5369 - mean_absolute_error: 2.2102\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 3s 267us/step - loss: 13.9786 - mean_absolute_error: 2.1544\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 3s 273us/step - loss: 13.7070 - mean_absolute_error: 2.1144\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 3s 280us/step - loss: 12.9399 - mean_absolute_error: 2.0766\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 12.3902 - mean_absolute_error: 2.0313\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 3s 262us/step - loss: 12.3767 - mean_absolute_error: 2.0109\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 3s 254us/step - loss: 12.0239 - mean_absolute_error: 1.9840\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 3s 280us/step - loss: 11.6297 - mean_absolute_error: 1.9478\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 3s 299us/step - loss: 11.2826 - mean_absolute_error: 1.9157\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 3s 289us/step - loss: 11.2246 - mean_absolute_error: 1.9053\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 3s 277us/step - loss: 11.2968 - mean_absolute_error: 1.8950\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 3s 261us/step - loss: 10.9780 - mean_absolute_error: 1.8509\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 10.9668 - mean_absolute_error: 1.8409\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 10.0276 - mean_absolute_error: 1.7951\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 3s 241us/step - loss: 10.6261 - mean_absolute_error: 1.8119\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 10.7524 - mean_absolute_error: 1.8168\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 3s 264us/step - loss: 9.9765 - mean_absolute_error: 1.7776\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 3s 243us/step - loss: 9.8291 - mean_absolute_error: 1.7548\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 3s 255us/step - loss: 9.4917 - mean_absolute_error: 1.7407\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 3s 257us/step - loss: 9.4529 - mean_absolute_error: 1.7395\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 3s 270us/step - loss: 9.7607 - mean_absolute_error: 1.7517\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 3s 251us/step - loss: 9.2301 - mean_absolute_error: 1.7122\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 9.1222 - mean_absolute_error: 1.6964\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 2s 240us/step - loss: 9.6195 - mean_absolute_error: 1.7203\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 2s 235us/step - loss: 8.9187 - mean_absolute_error: 1.6722\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 3s 241us/step - loss: 8.9522 - mean_absolute_error: 1.6775\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 2s 236us/step - loss: 8.6756 - mean_absolute_error: 1.6600\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 8.4293 - mean_absolute_error: 1.6362\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 3s 268us/step - loss: 8.7524 - mean_absolute_error: 1.6409\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 8.9188 - mean_absolute_error: 1.6527\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 8.5396 - mean_absolute_error: 1.6244\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 3s 262us/step - loss: 8.8260 - mean_absolute_error: 1.6489\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 8.5328 - mean_absolute_error: 1.6317\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 8.0938 - mean_absolute_error: 1.5969\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 2s 238us/step - loss: 8.2543 - mean_absolute_error: 1.6024\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 3s 264us/step - loss: 8.0817 - mean_absolute_error: 1.5840\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 3s 296us/step - loss: 8.3000 - mean_absolute_error: 1.6080\n",
      "Kappa Score: 0.9579713971531276\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/py3.6/lib/python3.6/site-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 4s 401us/step - loss: 63.4268 - mean_absolute_error: 4.3146\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 2s 206us/step - loss: 39.4304 - mean_absolute_error: 3.5011\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 2s 216us/step - loss: 33.5456 - mean_absolute_error: 3.4363\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 2s 207us/step - loss: 30.8772 - mean_absolute_error: 3.3822\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 2s 209us/step - loss: 29.8379 - mean_absolute_error: 3.3222\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 2s 212us/step - loss: 28.2381 - mean_absolute_error: 3.2254\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 2s 240us/step - loss: 27.5465 - mean_absolute_error: 3.0936\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 2s 217us/step - loss: 23.5518 - mean_absolute_error: 2.8448\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 2s 204us/step - loss: 20.9280 - mean_absolute_error: 2.6756\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 3s 266us/step - loss: 18.9779 - mean_absolute_error: 2.52541s -\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 3s 322us/step - loss: 16.8033 - mean_absolute_error: 2.3749\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 3s 303us/step - loss: 16.3531 - mean_absolute_error: 2.3217\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 4s 340us/step - loss: 15.3118 - mean_absolute_error: 2.2428\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 3s 296us/step - loss: 14.5050 - mean_absolute_error: 2.1850\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 3s 284us/step - loss: 13.7128 - mean_absolute_error: 2.1145\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 3s 278us/step - loss: 13.1732 - mean_absolute_error: 2.0814\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 3s 312us/step - loss: 13.4997 - mean_absolute_error: 2.0659\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 3s 320us/step - loss: 12.8622 - mean_absolute_error: 2.0350\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 3s 324us/step - loss: 11.9502 - mean_absolute_error: 1.9791\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 3s 330us/step - loss: 12.3098 - mean_absolute_error: 1.9623\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 4s 341us/step - loss: 11.4666 - mean_absolute_error: 1.9040\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 4s 369us/step - loss: 11.0435 - mean_absolute_error: 1.8801\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 3s 301us/step - loss: 10.4273 - mean_absolute_error: 1.8470\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 3s 283us/step - loss: 10.7696 - mean_absolute_error: 1.8678\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 11.0165 - mean_absolute_error: 1.8437\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 3s 242us/step - loss: 10.1836 - mean_absolute_error: 1.8051\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 3s 241us/step - loss: 10.4375 - mean_absolute_error: 1.7985\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 2s 228us/step - loss: 10.1027 - mean_absolute_error: 1.7838\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 2s 228us/step - loss: 10.3255 - mean_absolute_error: 1.7746\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 10.0224 - mean_absolute_error: 1.7568\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 3s 248us/step - loss: 9.5733 - mean_absolute_error: 1.7253\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 3s 252us/step - loss: 9.7309 - mean_absolute_error: 1.7173\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 2s 226us/step - loss: 9.6948 - mean_absolute_error: 1.7197\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 2s 225us/step - loss: 9.7204 - mean_absolute_error: 1.7055\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 9.3366 - mean_absolute_error: 1.6989\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 3s 243us/step - loss: 9.6996 - mean_absolute_error: 1.7063\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 3s 256us/step - loss: 8.9045 - mean_absolute_error: 1.6552\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 3s 266us/step - loss: 9.1001 - mean_absolute_error: 1.6579\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 3s 263us/step - loss: 9.2154 - mean_absolute_error: 1.6672\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 3s 270us/step - loss: 8.8196 - mean_absolute_error: 1.6462\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 2s 238us/step - loss: 9.0309 - mean_absolute_error: 1.6543\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 2s 230us/step - loss: 8.7357 - mean_absolute_error: 1.6449\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 2s 233us/step - loss: 8.8894 - mean_absolute_error: 1.6480\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 2s 236us/step - loss: 8.4811 - mean_absolute_error: 1.6168\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 3s 243us/step - loss: 8.5003 - mean_absolute_error: 1.6043\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 3s 250us/step - loss: 8.2933 - mean_absolute_error: 1.5896\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 2s 227us/step - loss: 8.3923 - mean_absolute_error: 1.6011\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 2s 229us/step - loss: 8.2082 - mean_absolute_error: 1.5805\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 2s 218us/step - loss: 8.5089 - mean_absolute_error: 1.6003\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 2s 220us/step - loss: 8.4523 - mean_absolute_error: 1.5887\n",
      "Kappa Score: 0.9639711298282064\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/py3.6/lib/python3.6/site-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 4s 407us/step - loss: 61.8826 - mean_absolute_error: 4.2806\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 2s 202us/step - loss: 37.2169 - mean_absolute_error: 3.4191\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 2s 206us/step - loss: 31.9202 - mean_absolute_error: 3.3601\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 2s 206us/step - loss: 28.9677 - mean_absolute_error: 3.2703\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 2s 217us/step - loss: 27.9486 - mean_absolute_error: 3.2301\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 2s 212us/step - loss: 26.9960 - mean_absolute_error: 3.1370\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 3s 271us/step - loss: 24.9900 - mean_absolute_error: 2.9676\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 23.0758 - mean_absolute_error: 2.7953\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 20.4952 - mean_absolute_error: 2.6302\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 2s 221us/step - loss: 18.1412 - mean_absolute_error: 2.4774\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 2s 219us/step - loss: 17.5700 - mean_absolute_error: 2.3986\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 2s 211us/step - loss: 15.9742 - mean_absolute_error: 2.3066\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 2s 213us/step - loss: 14.9309 - mean_absolute_error: 2.2183\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 2s 208us/step - loss: 15.1845 - mean_absolute_error: 2.2098\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 2s 214us/step - loss: 14.2543 - mean_absolute_error: 2.1560\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 2s 237us/step - loss: 13.1837 - mean_absolute_error: 2.0773\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 3s 245us/step - loss: 13.3700 - mean_absolute_error: 2.0889\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 3s 249us/step - loss: 12.7677 - mean_absolute_error: 2.0358\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 3s 262us/step - loss: 12.3087 - mean_absolute_error: 1.9953\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 3s 252us/step - loss: 11.6096 - mean_absolute_error: 1.9491\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 2s 224us/step - loss: 11.5725 - mean_absolute_error: 1.9381\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 2s 235us/step - loss: 11.1548 - mean_absolute_error: 1.8959\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 2s 222us/step - loss: 11.5054 - mean_absolute_error: 1.9029\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 2s 231us/step - loss: 10.7767 - mean_absolute_error: 1.8545\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 2s 230us/step - loss: 10.2364 - mean_absolute_error: 1.7970\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 2s 227us/step - loss: 10.5960 - mean_absolute_error: 1.8162\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 2s 226us/step - loss: 10.1715 - mean_absolute_error: 1.7766\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 2s 234us/step - loss: 10.0831 - mean_absolute_error: 1.7635\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 2s 234us/step - loss: 9.8051 - mean_absolute_error: 1.7356\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 2s 230us/step - loss: 9.9704 - mean_absolute_error: 1.7423\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 3s 241us/step - loss: 9.4976 - mean_absolute_error: 1.7267\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 3s 267us/step - loss: 9.4476 - mean_absolute_error: 1.7138\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 2s 239us/step - loss: 9.1847 - mean_absolute_error: 1.7040\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 2s 236us/step - loss: 9.3774 - mean_absolute_error: 1.6904\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 2s 236us/step - loss: 8.7250 - mean_absolute_error: 1.6587\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 2s 229us/step - loss: 9.1428 - mean_absolute_error: 1.6796\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 3s 242us/step - loss: 9.0874 - mean_absolute_error: 1.6817\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 3s 262us/step - loss: 9.0906 - mean_absolute_error: 1.6677\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 3s 264us/step - loss: 8.9142 - mean_absolute_error: 1.6657\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 2s 225us/step - loss: 8.9277 - mean_absolute_error: 1.6450\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 2s 228us/step - loss: 8.5371 - mean_absolute_error: 1.6161\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 2s 233us/step - loss: 8.4885 - mean_absolute_error: 1.6132\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 2s 233us/step - loss: 8.4494 - mean_absolute_error: 1.6227\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 2s 234us/step - loss: 8.3584 - mean_absolute_error: 1.6133\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 2s 234us/step - loss: 8.3698 - mean_absolute_error: 1.6158\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 2s 222us/step - loss: 8.3598 - mean_absolute_error: 1.6150\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 2s 225us/step - loss: 8.5945 - mean_absolute_error: 1.6039\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 2s 226us/step - loss: 8.1254 - mean_absolute_error: 1.5784\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 2s 226us/step - loss: 7.9678 - mean_absolute_error: 1.5747\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 2s 219us/step - loss: 8.0190 - mean_absolute_error: 1.5638\n",
      "Kappa Score: 0.9572098642386482\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/py3.6/lib/python3.6/site-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 4s 431us/step - loss: 63.6519 - mean_absolute_error: 4.3483\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 2s 206us/step - loss: 39.0443 - mean_absolute_error: 3.4878\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 2s 203us/step - loss: 32.8428 - mean_absolute_error: 3.4098\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 2s 209us/step - loss: 30.2764 - mean_absolute_error: 3.3467\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 2s 207us/step - loss: 28.7615 - mean_absolute_error: 3.2643\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 2s 203us/step - loss: 27.8119 - mean_absolute_error: 3.1742\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 2s 208us/step - loss: 26.5344 - mean_absolute_error: 3.0250\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 2s 216us/step - loss: 23.1525 - mean_absolute_error: 2.8243\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 2s 206us/step - loss: 20.9133 - mean_absolute_error: 2.6694\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 2s 209us/step - loss: 18.5122 - mean_absolute_error: 2.5250\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 2s 215us/step - loss: 17.4485 - mean_absolute_error: 2.4005\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 2s 206us/step - loss: 16.5917 - mean_absolute_error: 2.3547\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 2s 204us/step - loss: 15.8964 - mean_absolute_error: 2.3123\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 2s 216us/step - loss: 15.0474 - mean_absolute_error: 2.2217\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 2s 233us/step - loss: 14.4774 - mean_absolute_error: 2.1792\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 2s 222us/step - loss: 14.2953 - mean_absolute_error: 2.1592\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 2s 235us/step - loss: 13.1629 - mean_absolute_error: 2.0946\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 2s 217us/step - loss: 12.8523 - mean_absolute_error: 2.0257\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 2s 214us/step - loss: 12.6171 - mean_absolute_error: 2.0364\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 2s 223us/step - loss: 11.9153 - mean_absolute_error: 1.9798\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 2s 235us/step - loss: 11.7277 - mean_absolute_error: 1.9554\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 2s 223us/step - loss: 11.5216 - mean_absolute_error: 1.9401\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 11.0818 - mean_absolute_error: 1.8796\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 3s 253us/step - loss: 10.8631 - mean_absolute_error: 1.8551\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 3s 263us/step - loss: 11.0904 - mean_absolute_error: 1.8796\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 3s 261us/step - loss: 10.9001 - mean_absolute_error: 1.8443\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 2s 233us/step - loss: 9.9402 - mean_absolute_error: 1.7852\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 2s 227us/step - loss: 10.0061 - mean_absolute_error: 1.7852\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 2s 226us/step - loss: 10.0048 - mean_absolute_error: 1.7823\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 2s 225us/step - loss: 10.2083 - mean_absolute_error: 1.7769\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 2s 233us/step - loss: 9.9961 - mean_absolute_error: 1.7726\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 3s 242us/step - loss: 9.6650 - mean_absolute_error: 1.7356\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 2s 235us/step - loss: 9.1590 - mean_absolute_error: 1.7151\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 3s 247us/step - loss: 9.4278 - mean_absolute_error: 1.7216\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 3s 255us/step - loss: 9.2817 - mean_absolute_error: 1.7102\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 3s 286us/step - loss: 8.8282 - mean_absolute_error: 1.6742\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 3s 261us/step - loss: 9.1980 - mean_absolute_error: 1.7020\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 2s 235us/step - loss: 9.2300 - mean_absolute_error: 1.6937\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 2s 238us/step - loss: 8.8066 - mean_absolute_error: 1.6638\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 9.0515 - mean_absolute_error: 1.6911\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 2s 235us/step - loss: 9.0215 - mean_absolute_error: 1.6679\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 2s 234us/step - loss: 9.0269 - mean_absolute_error: 1.6635\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 3s 241us/step - loss: 8.5078 - mean_absolute_error: 1.6328\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 2s 238us/step - loss: 8.9041 - mean_absolute_error: 1.6660\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 3s 242us/step - loss: 8.7074 - mean_absolute_error: 1.6227\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 2s 236us/step - loss: 8.7776 - mean_absolute_error: 1.6445\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 2s 239us/step - loss: 8.1830 - mean_absolute_error: 1.5867\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 3s 246us/step - loss: 8.1421 - mean_absolute_error: 1.5988\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 3s 242us/step - loss: 8.6438 - mean_absolute_error: 1.6189\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 3s 244us/step - loss: 8.1607 - mean_absolute_error: 1.5946\n",
      "Kappa Score: 0.9605539327375521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "results = []\n",
    "y_pred_list = []\n",
    "\n",
    "count = 1\n",
    "for traincv, testcv in cv.split(X):\n",
    "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "    \n",
    "    train_essays = X_train['essay']\n",
    "    test_essays = X_test['essay']\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    for essay in train_essays:\n",
    "            # Obtaining all sentences from the training essays.\n",
    "            sentences += essay_to_sentences(essay, remove_stopwords = True)\n",
    "            \n",
    "    # Initializing variables for word2vec model.\n",
    "    num_features = 300 \n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    print(\"Training Word2Vec Model...\")\n",
    "    model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "    model.init_sims(replace=True)\n",
    "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "\n",
    "    clean_train_essays = []\n",
    "    \n",
    "    # Generate training and testing data word vectors.\n",
    "    for essay_v in train_essays:\n",
    "        clean_train_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n",
    "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
    "    \n",
    "    clean_test_essays = []\n",
    "    for essay_v in test_essays:\n",
    "        clean_test_essays.append(essay_to_wordlist( essay_v, remove_stopwords=True ))\n",
    "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
    "    \n",
    "    trainDataVecs = np.array(trainDataVecs)\n",
    "    testDataVecs = np.array(testDataVecs)\n",
    "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "    \n",
    "    lstm_model = get_model()\n",
    "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
    "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
    "    y_pred = lstm_model.predict(testDataVecs)\n",
    "    \n",
    "    # Save any one of the 8 models.\n",
    "    if count == 5:\n",
    "         lstm_model.save('./model_weights/final_lstm.h5')\n",
    "    \n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred = np.around(y_pred)\n",
    "    \n",
    "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
    "    print(\"Kappa Score: {}\".format(result))\n",
    "    results.append(result)\n",
    "\n",
    "    count += 1\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Avg. Kappa Score is 0.961 which is the highest we have ever seen on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Kappa score after a 5-fold cross validation:  0.9592\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Kappa score after a 5-fold cross validation: \",np.around(np.array(results).mean(),decimals=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
