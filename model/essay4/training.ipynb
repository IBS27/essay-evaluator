{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 14:08:41.197283: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training_set.tsv\", sep='\\t', encoding='ISO-8859-1');\n",
    "df.dropna(axis=1,inplace=True)\n",
    "df.drop(columns=['domain1_score','rater1_domain1','rater2_domain1'],inplace=True,axis=1)\n",
    "df.head()\n",
    "temp = pd.read_csv(\"Processed_data.csv\")\n",
    "temp.drop(\"Unnamed: 0\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>In this memoir of Narciso Rodriguez, @PERSON3'...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Throughout the excerpt from Home the Blueprint...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The mood the author created in the memoir is l...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>The mood created by the author is showing how ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The mood created in the memoir is happiness an...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          5  In this memoir of Narciso Rodriguez, @PERSON3'...   \n",
       "1         2          5  Throughout the excerpt from Home the Blueprint...   \n",
       "2         3          5  The mood the author created in the memoir is l...   \n",
       "3         4          5  The mood created by the author is showing how ...   \n",
       "4         5          5  The mood created in the memoir is happiness an...   \n",
       "\n",
       "   domain1_score  \n",
       "0              5  \n",
       "1              5  \n",
       "2              8  \n",
       "3              2  \n",
       "4              8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['domain1_score']=temp['final_score']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In this memoir of Narciso Rodriguez, @PERSON3's life, the mood containing it all, was greatful, and showed how his parents gave him love through his whole life. Both his parents were born and raised in Cuba, and in 1956, they both moved to the United States. Starting their lives over again, and taking any job they could find. Then in 1961, @PERSON2, @CAPS1. was born. Both Parents raised him with love, and care, and introducing his Cuban background into his life.        As @PERSON2, was telling his story, all readers could tell how greatful he was to have a family like he did. Also, as he shared his non-Ã¢\\x80\\x93 blood related family, and the remembrence on how his parents' life changed by moving to @LOCATION2, he showed the respect he had towards them.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['essay'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>final_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>spell_err_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>In this memoir of Narciso Rodriguez, life, the...</td>\n",
       "      <td>5</td>\n",
       "      <td>In memoir Narciso Rodriguez  life  mood contai...</td>\n",
       "      <td>547</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>4.307087</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Throughout the excerpt from Home the Blueprint...</td>\n",
       "      <td>5</td>\n",
       "      <td>Throughout excerpt Home Blueprints Our Lives  ...</td>\n",
       "      <td>720</td>\n",
       "      <td>168</td>\n",
       "      <td>7</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>11</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>The mood the author created in the memoir is l...</td>\n",
       "      <td>8</td>\n",
       "      <td>The mood author created memoir love  author fi...</td>\n",
       "      <td>500</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>The mood created by the author is showing how ...</td>\n",
       "      <td>2</td>\n",
       "      <td>The mood created author showing cuban s lived ...</td>\n",
       "      <td>307</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>4.205479</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>The mood created in the memoir is happiness an...</td>\n",
       "      <td>8</td>\n",
       "      <td>The mood created memoir happiness gratitude  N...</td>\n",
       "      <td>535</td>\n",
       "      <td>126</td>\n",
       "      <td>8</td>\n",
       "      <td>4.246032</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          5  In this memoir of Narciso Rodriguez, life, the...   \n",
       "1         2          5  Throughout the excerpt from Home the Blueprint...   \n",
       "2         3          5  The mood the author created in the memoir is l...   \n",
       "3         4          5  The mood created by the author is showing how ...   \n",
       "4         5          5  The mood created in the memoir is happiness an...   \n",
       "\n",
       "   final_score                                        clean_essay  char_count  \\\n",
       "0            5  In memoir Narciso Rodriguez  life  mood contai...         547   \n",
       "1            5  Throughout excerpt Home Blueprints Our Lives  ...         720   \n",
       "2            8  The mood author created memoir love  author fi...         500   \n",
       "3            2  The mood created author showing cuban s lived ...         307   \n",
       "4            8  The mood created memoir happiness gratitude  N...         535   \n",
       "\n",
       "   word_count  sent_count  avg_word_len  spell_err_count  noun_count  \\\n",
       "0         127           7      4.307087                5          29   \n",
       "1         168           7      4.285714               11          37   \n",
       "2         110           6      4.545455                6          34   \n",
       "3          73           3      4.205479                8          16   \n",
       "4         126           8      4.246032                4          28   \n",
       "\n",
       "   adj_count  verb_count  adv_count  \n",
       "0         28           4          3  \n",
       "1         31          14         12  \n",
       "2         19           9          4  \n",
       "3         15           8          1  \n",
       "4         22          11          9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Dataset\n",
    "y = df['domain1_score']\n",
    "df.drop('domain1_score',inplace=True,axis=1)\n",
    "X=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1263, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e = X_train['essay'].tolist()\n",
    "test_e = X_test['essay'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents=[]\n",
    "test_sents=[]\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def sent2word(x):\n",
    "    x=re.sub(\"[^A-Za-z]\",\" \",x)\n",
    "    x.lower()\n",
    "    filtered_sentence = [] \n",
    "    words=x.split()\n",
    "    for w in words:\n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "def essay2word(essay):\n",
    "    essay = essay.strip()\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw = tokenizer.tokenize(essay)\n",
    "    final_words=[]\n",
    "    for i in raw:\n",
    "        if(len(i)>0):\n",
    "            final_words.append(sent2word(i))\n",
    "    return final_words\n",
    "\n",
    "for i in train_e:\n",
    "    train_sents+=essay2word(i)\n",
    "\n",
    "for i in test_e:\n",
    "    test_sents+=essay2word(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8407"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'mood', 'created', 'author', 'memoir', 'sense', 'family']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing WORD2VEC and LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/gnm3d9hn21d8t3q08syhwsdw0000gp/T/ipykernel_6778/1462232201.py:15: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "#Training Word2Vec model\n",
    "num_features = 300 \n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3\n",
    "\n",
    "model = Word2Vec(train_sents, \n",
    "                 workers=num_workers, \n",
    "                 vector_size=num_features, \n",
    "                 min_count = min_word_count, \n",
    "                 window = context, \n",
    "                 sample = downsampling)\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeVec(words, model, num_features):\n",
    "    vec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    noOfWords = 0.\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    for i in words:\n",
    "        if i in index2word_set:\n",
    "            noOfWords += 1\n",
    "            vec = np.add(vec,model.wv.get_vector(i))        \n",
    "    vec = np.divide(vec,noOfWords)\n",
    "    return vec\n",
    "\n",
    "\n",
    "def getVecs(essays, model, num_features):\n",
    "    c=0\n",
    "    essay_vecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for i in essays:\n",
    "        essay_vecs[c] = makeVec(i, model, num_features)\n",
    "        c+=1\n",
    "    return essay_vecs\n",
    "\n",
    "\n",
    "clean_train=[]\n",
    "for i in train_e:\n",
    "    clean_train.append(sent2word(i))\n",
    "training_vectors = getVecs(clean_train, model, num_features)\n",
    "\n",
    "clean_test=[] \n",
    "\n",
    "for i in test_e:\n",
    "    clean_test.append(sent2word(i))\n",
    "testing_vectors = getVecs(clean_test, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1263, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 14:09:14.010785: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_vectors = np.array(training_vectors)\n",
    "testing_vectors = np.array(testing_vectors)\n",
    "\n",
    "# Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
    "testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
    "lstm_model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1263, 1, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING AND PREDICTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "20/20 [==============================] - 5s 13ms/step - loss: 29.5296 - mae: 4.6946\n",
      "Epoch 2/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 8.9859 - mae: 2.5051\n",
      "Epoch 3/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 8.0843 - mae: 2.3799\n",
      "Epoch 4/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 7.6926 - mae: 2.3429\n",
      "Epoch 5/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 7.6804 - mae: 2.3178\n",
      "Epoch 6/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.9927 - mae: 2.2084\n",
      "Epoch 7/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.9867 - mae: 2.2178\n",
      "Epoch 8/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.6904 - mae: 2.1876\n",
      "Epoch 9/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.8162 - mae: 2.1822\n",
      "Epoch 10/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.7224 - mae: 2.1551\n",
      "Epoch 11/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.7432 - mae: 2.1803\n",
      "Epoch 12/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.7112 - mae: 2.1684\n",
      "Epoch 13/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.5603 - mae: 2.1391\n",
      "Epoch 14/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.3703 - mae: 2.0972\n",
      "Epoch 15/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.5625 - mae: 2.1248\n",
      "Epoch 16/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 6.3467 - mae: 2.0713\n",
      "Epoch 17/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.3822 - mae: 2.1068\n",
      "Epoch 18/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.2641 - mae: 2.0962\n",
      "Epoch 19/150\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 6.4096 - mae: 2.1048\n",
      "Epoch 20/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.4453 - mae: 2.0951\n",
      "Epoch 21/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.2476 - mae: 2.0628\n",
      "Epoch 22/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.3191 - mae: 2.0806\n",
      "Epoch 23/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.2285 - mae: 2.0577\n",
      "Epoch 24/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.2620 - mae: 2.0778\n",
      "Epoch 25/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.2144 - mae: 2.0687\n",
      "Epoch 26/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 6.2842 - mae: 2.0967\n",
      "Epoch 27/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.0289 - mae: 2.0404\n",
      "Epoch 28/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.1060 - mae: 2.0401\n",
      "Epoch 29/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.3218 - mae: 2.0759\n",
      "Epoch 30/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.4375 - mae: 2.1094\n",
      "Epoch 31/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.9952 - mae: 2.0276\n",
      "Epoch 32/150\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 5.9151 - mae: 2.0288\n",
      "Epoch 33/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.1060 - mae: 2.0635\n",
      "Epoch 34/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.1105 - mae: 2.0436\n",
      "Epoch 35/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.9796 - mae: 2.0121\n",
      "Epoch 36/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 6.0441 - mae: 2.0200\n",
      "Epoch 37/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.2043 - mae: 2.0664\n",
      "Epoch 38/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.1073 - mae: 2.0579\n",
      "Epoch 39/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.0680 - mae: 2.0436\n",
      "Epoch 40/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.0574 - mae: 2.0457\n",
      "Epoch 41/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.9621 - mae: 2.0095\n",
      "Epoch 42/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 6.0598 - mae: 2.0348\n",
      "Epoch 43/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.7837 - mae: 1.9977\n",
      "Epoch 44/150\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 6.2039 - mae: 2.0700\n",
      "Epoch 45/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.8798 - mae: 2.0263\n",
      "Epoch 46/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.9595 - mae: 2.0097\n",
      "Epoch 47/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.1061 - mae: 2.0423\n",
      "Epoch 48/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 6.3534 - mae: 2.0928\n",
      "Epoch 49/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.9247 - mae: 2.0246\n",
      "Epoch 50/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.9303 - mae: 2.0279\n",
      "Epoch 51/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.8098 - mae: 2.0088\n",
      "Epoch 52/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.2328 - mae: 2.0622\n",
      "Epoch 53/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.9979 - mae: 2.0271\n",
      "Epoch 54/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.9510 - mae: 2.0354\n",
      "Epoch 55/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.0609 - mae: 2.0520\n",
      "Epoch 56/150\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 5.9504 - mae: 2.0294\n",
      "Epoch 57/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.9254 - mae: 2.0377\n",
      "Epoch 58/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.0039 - mae: 2.0242\n",
      "Epoch 59/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.9948 - mae: 2.0297\n",
      "Epoch 60/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.8844 - mae: 2.0049\n",
      "Epoch 61/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 6.1484 - mae: 2.0798\n",
      "Epoch 62/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.0241 - mae: 2.0328\n",
      "Epoch 63/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.9422 - mae: 2.0470\n",
      "Epoch 64/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.0437 - mae: 2.0303\n",
      "Epoch 65/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.7788 - mae: 1.9897\n",
      "Epoch 66/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.9313 - mae: 2.0242\n",
      "Epoch 67/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.9675 - mae: 2.0190\n",
      "Epoch 68/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.9791 - mae: 2.0221\n",
      "Epoch 69/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.0006 - mae: 2.0470\n",
      "Epoch 70/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.1021 - mae: 2.0484\n",
      "Epoch 71/150\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 5.9946 - mae: 2.0186\n",
      "Epoch 72/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.0423 - mae: 2.0486\n",
      "Epoch 73/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.0021 - mae: 2.0329\n",
      "Epoch 74/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.6905 - mae: 1.9757\n",
      "Epoch 75/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.9969 - mae: 2.0252\n",
      "Epoch 76/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.8625 - mae: 2.0002\n",
      "Epoch 77/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.8354 - mae: 2.0166\n",
      "Epoch 78/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.8533 - mae: 1.9947\n",
      "Epoch 79/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.8882 - mae: 2.0139\n",
      "Epoch 80/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.9739 - mae: 2.0195\n",
      "Epoch 81/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 6.0274 - mae: 2.0326\n",
      "Epoch 82/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.9698 - mae: 2.0378\n",
      "Epoch 83/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.9376 - mae: 2.0256\n",
      "Epoch 84/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.7443 - mae: 1.9974\n",
      "Epoch 85/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.8119 - mae: 2.0052\n",
      "Epoch 86/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.7028 - mae: 1.9723\n",
      "Epoch 87/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.8075 - mae: 2.0041\n",
      "Epoch 88/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.9573 - mae: 2.0215\n",
      "Epoch 89/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.7083 - mae: 1.9768\n",
      "Epoch 90/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.8748 - mae: 2.0047\n",
      "Epoch 91/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 6.0280 - mae: 2.0386\n",
      "Epoch 92/150\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 5.9960 - mae: 2.0495\n",
      "Epoch 93/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.7232 - mae: 1.9789\n",
      "Epoch 94/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.6994 - mae: 1.9481\n",
      "Epoch 95/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.8315 - mae: 1.9968\n",
      "Epoch 96/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.8185 - mae: 1.9936\n",
      "Epoch 97/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.8509 - mae: 2.0125\n",
      "Epoch 98/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.8838 - mae: 1.9999\n",
      "Epoch 99/150\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 5.8109 - mae: 1.9997\n",
      "Epoch 100/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.8840 - mae: 2.0007\n",
      "Epoch 101/150\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 5.9962 - mae: 2.0415\n",
      "Epoch 102/150\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 5.8214 - mae: 2.0116\n",
      "Epoch 103/150\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 5.6504 - mae: 1.9734\n",
      "Epoch 104/150\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 5.9215 - mae: 2.0178\n",
      "Epoch 105/150\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 5.8659 - mae: 2.0093\n",
      "Epoch 106/150\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 5.8571 - mae: 2.0125\n",
      "Epoch 107/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.7719 - mae: 1.9920\n",
      "Epoch 108/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.5962 - mae: 1.9517\n",
      "Epoch 109/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.7354 - mae: 1.9824\n",
      "Epoch 110/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.7860 - mae: 2.0026\n",
      "Epoch 111/150\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 5.7103 - mae: 1.9651\n",
      "Epoch 112/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.7011 - mae: 1.9802\n",
      "Epoch 113/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.6918 - mae: 1.9606\n",
      "Epoch 114/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.8218 - mae: 2.0082\n",
      "Epoch 115/150\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 5.6716 - mae: 1.9729\n",
      "Epoch 116/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.7945 - mae: 1.9928\n",
      "Epoch 117/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.8401 - mae: 2.0014\n",
      "Epoch 118/150\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 5.6953 - mae: 1.9775\n",
      "Epoch 119/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.8352 - mae: 1.9806\n",
      "Epoch 120/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.7754 - mae: 2.0006\n",
      "Epoch 121/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.6894 - mae: 1.9799\n",
      "Epoch 122/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.8031 - mae: 1.9943\n",
      "Epoch 123/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.7399 - mae: 1.9705\n",
      "Epoch 124/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.8485 - mae: 2.0048\n",
      "Epoch 125/150\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 5.7616 - mae: 1.9870\n",
      "Epoch 126/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.6422 - mae: 1.9700\n",
      "Epoch 127/150\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 5.8036 - mae: 2.0071\n",
      "Epoch 128/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.9273 - mae: 1.9965\n",
      "Epoch 129/150\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 5.7116 - mae: 1.9842\n",
      "Epoch 130/150\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 5.7395 - mae: 1.9774\n",
      "Epoch 131/150\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 5.8863 - mae: 2.0254\n",
      "Epoch 132/150\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 5.7197 - mae: 1.9892\n",
      "Epoch 133/150\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 5.8524 - mae: 1.9874\n",
      "Epoch 134/150\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 5.9005 - mae: 2.0209\n",
      "Epoch 135/150\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 5.6580 - mae: 1.9646\n",
      "Epoch 136/150\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 5.6961 - mae: 1.9674\n",
      "Epoch 137/150\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 5.5429 - mae: 1.9286\n",
      "Epoch 138/150\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 5.7017 - mae: 1.9827\n",
      "Epoch 139/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.6296 - mae: 1.9588\n",
      "Epoch 140/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.4811 - mae: 1.9446\n",
      "Epoch 141/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.6531 - mae: 1.9606\n",
      "Epoch 142/150\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 5.7382 - mae: 1.9761\n",
      "Epoch 143/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.6830 - mae: 1.9914\n",
      "Epoch 144/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.8226 - mae: 2.0063\n",
      "Epoch 145/150\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 5.6661 - mae: 1.9661\n",
      "Epoch 146/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.4551 - mae: 1.9270\n",
      "Epoch 147/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.4911 - mae: 1.9322\n",
      "Epoch 148/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.7965 - mae: 1.9981\n",
      "Epoch 149/150\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 5.5076 - mae: 1.9296\n",
      "Epoch 150/150\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 5.8002 - mae: 1.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe5b3e2d3c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(training_vectors, y_train, batch_size=64, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [8.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [8.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [3.],\n",
       "       [7.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [8.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [1.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [3.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [2.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [2.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [2.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [3.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [2.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [3.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [1.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [3.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [8.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [3.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [3.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [8.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [2.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [8.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [8.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [3.],\n",
       "       [6.],\n",
       "       [8.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [5.],\n",
       "       [2.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [4.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [3.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [8.],\n",
       "       [5.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [8.],\n",
       "       [8.],\n",
       "       [5.],\n",
       "       [8.],\n",
       "       [4.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [5.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [6.],\n",
       "       [7.],\n",
       "       [3.],\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [7.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.save('final_lstm.h5')\n",
    "y_pred = lstm_model.predict(testing_vectors)\n",
    "y_pred = np.around(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "essay_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
